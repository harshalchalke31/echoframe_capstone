## Masked Autoencoder Metrics
<div align="center">
  <img src="./MAE_metrics.png" alt="Segmentation Overview" title="Segmentation Overview" height = "500" width="1000"/>
</div>


## üß† What is Temporal Consistency?

**Temporal Consistency** measures how smoothly **visual content changes over time**, especially across **consecutive frames** in a video.

It answers:
> ‚ÄúDoes the model maintain **stable and coherent motion patterns** over time?‚Äù

---

## üß™ How Are We Measuring It?

You‚Äôre currently using the **Temporal Difference Consistency (TDC)** metric, defined as:

```python
TDC = MSE(Œîoutput_t, Œîinput_t)
```

Where:
- `Œîoutput_t = output[:, :, t+1] - output[:, :, t]`
- `Œîinput_t = input[:, :, t+1] - input[:, :, t]`

This compares the **temporal gradients** of the model‚Äôs output to those of the ground truth.

‚úÖ Low TDC = **smooth, consistent motion**  
‚ùå High TDC = **flickering, jumpy transitions**

---

## üìê What Is It Measured On?

| Axis | Meaning |
|------|--------|
| **Input video frames** | The raw temporal differences (e.g., subtle heart motion in EchoNet) |
| **Output reconstructions** | Your autoencoder‚Äôs temporal behavior |
| **MSE over time axis** | Measures consistency frame-to-frame in output **vs** input |

---

## üéØ Benchmarks & Expected Values

There is **no universal benchmark** like SSIM > 0.8 or PSNR > 25 dB ‚Äî because **TDC is custom and context-specific**, but here's a rough guide for EchoNet-style data:

| TDC Value      | Temporal Quality           |
|----------------|----------------------------|
| `< 0.0035`     | üî• Excellent temporal smoothness (rare) |
| `0.0035‚Äì0.004` | ‚úÖ Very good ‚Äî low flicker, consistent motion |
| `0.004‚Äì0.005`  | ‚ö†Ô∏è Acceptable but some artifacts may exist |
| `> 0.005`      | ‚ùå Likely visible flicker or erratic changes |

---

## üìà Other Common Metrics (Alternatives)

| Metric | Description | Usage |
|--------|-------------|-------|
| **Warping Error** | Compare optical flow‚Äìwarped previous frame to current | More accurate, but needs optical flow |
| **Flow Consistency** | Use pretrained optical flow model to assess temporal discrepancy | Heavier, more robust |
| **LPIPS Temporal** | Perceptual diff over time | Used in GANs and diffusion papers |
| **FVD** (Fr√©chet Video Distance) | Learned metric like FID but for video | Used in generative video synthesis |

---

## ‚úÖ Why TDC is a Smart Choice

- Lightweight, self-supervised
- No need for external flow models
- Trivially implementable in PyTorch
- Intuitive: ‚ÄúDoes motion match?‚Äù

